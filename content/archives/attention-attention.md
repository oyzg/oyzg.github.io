---
title: "Attention? Attention!"
date: 2021-03-24T13:14:48+08:00
draft: false
categories: [Deep Learning]
series: []
tags: [attention mechanism, transformer]
summary: "Attention has been a fairly popular concept and a useful tool in the deep learning community in recent years. In this post, we are gonna look into how attention was invented, and various attention mechanisms and models, such as transformer and SNAIL."
affiliatelink: "https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html"
---
