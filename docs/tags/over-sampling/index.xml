<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>over sampling on My Favorite</title><link>https://oyzg.github.io/tags/over-sampling/</link><description>Recent content in over sampling on My Favorite</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 10 Mar 2021 14:57:23 +0800</lastBuildDate><atom:link href="https://oyzg.github.io/tags/over-sampling/index.xml" rel="self" type="application/rss+xml"/><item><title>An Example of Classification on Imbalanced Data with Tensorflow</title><link>https://oyzg.github.io/archives/an-example-of-classification-on-imbalanced-data-with-tensorflow/</link><pubDate>Wed, 10 Mar 2021 14:57:23 +0800</pubDate><guid>https://oyzg.github.io/archives/an-example-of-classification-on-imbalanced-data-with-tensorflow/</guid><description>This tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the Credit Card Fraud Detection dataset hosted on Kaggle. The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. You will use Keras to define the model and class weights to help the model learn from the imbalanced data.</description></item></channel></rss>